{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Search with BrickKit\n",
    "\n",
    "This notebook demonstrates **end-to-end usage of BrickKit** for deploying a governed Vector Search solution.\n",
    "\n",
    "## What BrickKit Does\n",
    "\n",
    "BrickKit automates governance for Databricks resources:\n",
    "- **Naming conventions** - Environment-aware names (dev/acc/prd suffixes)\n",
    "- **Tagging** - Automatic cost center, team, compliance tags\n",
    "- **Ownership rules** - Enforce service principals for catalogs, groups for schemas\n",
    "- **Validation** - Catch governance violations before deployment\n",
    "\n",
    "## What This Demo Shows\n",
    "\n",
    "1. Load a governance convention from YAML\n",
    "2. Create sample data (or optionally fetch from World Bank API)\n",
    "3. Define governed resources using BrickKit models\n",
    "4. Deploy using BrickKit executors\n",
    "5. Test vector search\n",
    "6. See what governance BrickKit applied automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install databricks-vectorsearch databricks-sdk pydantic pyyaml --quiet\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "# Edit these widgets or override via job parameters\n",
    "\n",
    "dbutils.widgets.text(\"catalog\", \"quant_risk\", \"Catalog Name (base)\")\n",
    "dbutils.widgets.text(\"schema\", \"indicators\", \"Schema Name\")\n",
    "dbutils.widgets.dropdown(\"environment\", \"dev\", [\"dev\", \"acc\", \"prd\"], \"Environment\")\n",
    "dbutils.widgets.dropdown(\"dry_run\", \"true\", [\"true\", \"false\"], \"Dry Run\")\n",
    "\n",
    "# Read widget values\n",
    "CATALOG_BASE = dbutils.widgets.get(\"catalog\")\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"schema\")\n",
    "ENVIRONMENT = dbutils.widgets.get(\"environment\")\n",
    "DRY_RUN = dbutils.widgets.get(\"dry_run\").lower() == \"true\"\n",
    "\n",
    "# Derived names (will be suffixed by BrickKit based on environment)\n",
    "TABLE_NAME = \"worldbank_indicators\"\n",
    "ENDPOINT_NAME = \"quant_risk_search\"\n",
    "INDEX_NAME = f\"{TABLE_NAME}_index\"\n",
    "\n",
    "print(f\"Environment: {ENVIRONMENT}\")\n",
    "print(f\"Dry Run: {DRY_RUN}\")\n",
    "print(f\"Catalog (base): {CATALOG_BASE}\")\n",
    "print(f\"Schema: {SCHEMA_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS ===\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "# BrickKit imports\n",
    "from brickkit import (\n",
    "    Catalog,\n",
    "    Schema,\n",
    "    Tag,\n",
    "    SecurableType,\n",
    "    VectorSearchEndpoint,\n",
    "    VectorSearchIndex,\n",
    "    load_convention,\n",
    ")\n",
    "from brickkit.executors import (\n",
    "    CatalogExecutor,\n",
    "    SchemaExecutor,\n",
    "    VectorSearchEndpointExecutor,\n",
    "    VectorSearchIndexExecutor,\n",
    ")\n",
    "from brickkit.models.base import set_current_environment\n",
    "from brickkit.models.enums import Environment\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set BrickKit environment\n",
    "ENV_MAP = {\"dev\": Environment.DEV, \"acc\": Environment.ACC, \"prd\": Environment.PRD}\n",
    "set_current_environment(ENV_MAP[ENVIRONMENT])\n",
    "\n",
    "print(f\"BrickKit environment set to: {ENVIRONMENT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD GOVERNANCE CONVENTION ===\n",
    "# The convention defines naming patterns, required tags, and ownership rules\n",
    "\n",
    "CONVENTION_PATH = \"conventions/financial_services.yml\"\n",
    "convention = load_convention(CONVENTION_PATH)\n",
    "\n",
    "print(f\"Loaded convention: {convention.name} (v{convention.version})\")\n",
    "print(f\"Rules: {len(convention.schema.rules)}\")\n",
    "print(f\"Default tags: {len(convention.schema.tags)}\")\n",
    "\n",
    "# Show what the convention enforces\n",
    "for rule in convention.schema.rules:\n",
    "    mode = \"ENFORCED\" if rule.mode.value == \"enforced\" else \"ADVISORY\"\n",
    "    print(f\"  [{mode}] {rule.rule}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Sample Data\n",
    "\n",
    "We'll use a small inline dataset of World Bank indicators. This lets you run the full demo quickly without external API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAMPLE DATA ===\n",
    "# 20 World Bank indicators with embedding text for vector search\n",
    "\n",
    "SAMPLE_INDICATORS = [\n",
    "    (\"SP.POP.TOTL\", \"Population, total\", \"Total population counts all residents regardless of legal status or citizenship.\", \"Demographics\"),\n",
    "    (\"NY.GDP.MKTP.CD\", \"GDP (current US$)\", \"GDP at purchaser's prices is the sum of gross value added by all resident producers.\", \"Economy\"),\n",
    "    (\"NY.GDP.PCAP.CD\", \"GDP per capita (current US$)\", \"GDP per capita is gross domestic product divided by midyear population.\", \"Economy\"),\n",
    "    (\"SI.POV.DDAY\", \"Poverty headcount ratio at $2.15 a day\", \"Poverty headcount ratio at $2.15 a day is the percentage of the population living on less than $2.15 a day.\", \"Poverty\"),\n",
    "    (\"SI.POV.GINI\", \"Gini index\", \"Gini index measures the extent to which the distribution of income among individuals deviates from a perfectly equal distribution.\", \"Inequality\"),\n",
    "    (\"SL.UEM.TOTL.ZS\", \"Unemployment, total (% of labor force)\", \"Unemployment refers to the share of the labor force that is without work but available and seeking employment.\", \"Labor\"),\n",
    "    (\"FP.CPI.TOTL.ZG\", \"Inflation, consumer prices (annual %)\", \"Inflation as measured by the consumer price index reflects the annual percentage change in the cost of goods and services.\", \"Economy\"),\n",
    "    (\"SP.DYN.LE00.IN\", \"Life expectancy at birth, total (years)\", \"Life expectancy at birth indicates the number of years a newborn infant would live if patterns of mortality at birth were to stay the same.\", \"Health\"),\n",
    "    (\"SH.DYN.MORT\", \"Mortality rate, under-5 (per 1,000 live births)\", \"Under-five mortality rate is the probability per 1,000 that a newborn baby will die before reaching age five.\", \"Health\"),\n",
    "    (\"SE.ADT.LITR.ZS\", \"Literacy rate, adult total (% of people ages 15 and above)\", \"Adult literacy rate is the percentage of people ages 15 and above who can read and write a short simple statement.\", \"Education\"),\n",
    "    (\"SE.PRM.ENRR\", \"School enrollment, primary (% gross)\", \"Gross enrollment ratio is the ratio of total enrollment to the population of the age group that officially corresponds to the level of education.\", \"Education\"),\n",
    "    (\"EG.USE.ELEC.KH.PC\", \"Electric power consumption (kWh per capita)\", \"Electric power consumption measures the production of power plants and combined heat and power plants less transmission losses.\", \"Energy\"),\n",
    "    (\"EN.ATM.CO2E.PC\", \"CO2 emissions (metric tons per capita)\", \"Carbon dioxide emissions are those stemming from the burning of fossil fuels and the manufacture of cement.\", \"Environment\"),\n",
    "    (\"AG.LND.FRST.ZS\", \"Forest area (% of land area)\", \"Forest area is land under natural or planted stands of trees of at least 5 meters in situ.\", \"Environment\"),\n",
    "    (\"SH.XPD.CHEX.PC.CD\", \"Current health expenditure per capita (current US$)\", \"Current expenditures on health per capita in current US dollars.\", \"Health\"),\n",
    "    (\"IT.NET.USER.ZS\", \"Individuals using the Internet (% of population)\", \"Internet users are individuals who have used the Internet in the last 3 months.\", \"Technology\"),\n",
    "    (\"BX.KLT.DINV.CD.WD\", \"Foreign direct investment, net inflows (BoP, current US$)\", \"Foreign direct investment are the net inflows of investment to acquire a lasting management interest.\", \"Economy\"),\n",
    "    (\"GC.DOD.TOTL.GD.ZS\", \"Central government debt, total (% of GDP)\", \"Debt is the entire stock of direct government fixed-term contractual obligations to others outstanding.\", \"Economy\"),\n",
    "    (\"NE.EXP.GNFS.ZS\", \"Exports of goods and services (% of GDP)\", \"Exports of goods and services represent the value of all goods and other market services provided to the rest of the world.\", \"Trade\"),\n",
    "    (\"NE.IMP.GNFS.ZS\", \"Imports of goods and services (% of GDP)\", \"Imports of goods and services represent the value of all goods and other market services received from the rest of the world.\", \"Trade\"),\n",
    "]\n",
    "\n",
    "# Schema for the indicators table\n",
    "INDICATORS_SCHEMA = StructType([\n",
    "    StructField(\"indicator_id\", StringType(), False),\n",
    "    StructField(\"indicator_name\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"topic\", StringType(), True),\n",
    "    StructField(\"embedding_text\", StringType(), True),\n",
    "])\n",
    "\n",
    "def create_sample_dataframe(spark: SparkSession):\n",
    "    \"\"\"Create DataFrame from sample indicators with embedding text.\"\"\"\n",
    "    rows = [\n",
    "        (ind_id, name, desc, topic, f\"{name}. {desc}\")\n",
    "        for ind_id, name, desc, topic in SAMPLE_INDICATORS\n",
    "    ]\n",
    "    return spark.createDataFrame(rows, INDICATORS_SCHEMA)\n",
    "\n",
    "# Preview the sample data\n",
    "sample_df = create_sample_dataframe(spark)\n",
    "print(f\"Sample data: {sample_df.count()} indicators\")\n",
    "sample_df.select(\"indicator_id\", \"indicator_name\", \"topic\").show(5, truncate=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Fetch Real Data from World Bank API\n",
    "\n",
    "Uncomment and run the cell below to fetch real indicator metadata. This takes several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OPTIONAL: FETCH FROM WORLD BANK API ===\n",
    "# Uncomment this cell to fetch real data (takes several minutes)\n",
    "\n",
    "# %pip install wbgapi requests tqdm --quiet\n",
    "\n",
    "# import wbgapi as wb\n",
    "# import requests\n",
    "# from requests.exceptions import RequestException, Timeout\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def fetch_worldbank_indicators(spark: SparkSession, limit: int = 100):\n",
    "#     \"\"\"Fetch indicator metadata from World Bank API.\"\"\"\n",
    "#     series_list = wb.series.info()\n",
    "#     series_ids = [s.get(\"id\") for s in series_list.items][:limit]\n",
    "#     \n",
    "#     rows = []\n",
    "#     for series_id in tqdm(series_ids, desc=\"Fetching\"):\n",
    "#         try:\n",
    "#             url = f\"https://api.worldbank.org/v2/indicator/{series_id}?format=json\"\n",
    "#             resp = requests.get(url, timeout=30)\n",
    "#             resp.raise_for_status()\n",
    "#             data = resp.json()\n",
    "#             if len(data) >= 2 and data[1]:\n",
    "#                 meta = data[1][0]\n",
    "#                 name = meta.get(\"name\", \"\") or \"\"\n",
    "#                 desc = meta.get(\"sourceNote\", \"\") or \"\"\n",
    "#                 topics = meta.get(\"topics\", []) or []\n",
    "#                 topic = topics[0].get(\"value\", \"\") if topics else \"\"\n",
    "#                 embedding_text = f\"{name}. {desc}\".strip()\n",
    "#                 rows.append((series_id, name, desc, topic, embedding_text))\n",
    "#         except (RequestException, Timeout, ValueError) as e:\n",
    "#             print(f\"Skipping {series_id}: {e}\")\n",
    "#     \n",
    "#     return spark.createDataFrame(rows, INDICATORS_SCHEMA)\n",
    "\n",
    "# # Fetch real data (uncomment to use)\n",
    "# sample_df = fetch_worldbank_indicators(spark, limit=500)\n",
    "# print(f\"Fetched {sample_df.count()} indicators from World Bank API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Define Governed Resources\n",
    "\n",
    "Now we define our resources using BrickKit models. The convention automatically applies:\n",
    "- Environment-specific naming (e.g., `quant_risk_dev`)\n",
    "- Required governance tags\n",
    "- Ownership rules validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEFINE GOVERNED RESOURCES ===\n",
    "\n",
    "environment = ENV_MAP[ENVIRONMENT]\n",
    "\n",
    "# Get owners from convention (enforces SP for catalogs, Group for schemas)\n",
    "catalog_owner = convention.get_catalog_owner(environment)\n",
    "schema_owner = convention.get_owner(SecurableType.SCHEMA, environment)\n",
    "\n",
    "print(f\"Catalog owner: {catalog_owner.resolved_name} ({catalog_owner.principal_type.value})\")\n",
    "print(f\"Schema owner: {schema_owner.resolved_name} ({schema_owner.principal_type.value})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CATALOG ===\n",
    "catalog_name = convention.generate_name(SecurableType.CATALOG, environment)\n",
    "\n",
    "catalog = Catalog(\n",
    "    name=catalog_name,\n",
    "    owner=catalog_owner,\n",
    "    comment=\"Risk Analytics catalog for quantitative trading\",\n",
    ")\n",
    "\n",
    "# Apply convention (adds tags, validates rules)\n",
    "convention.apply_to(catalog, environment)\n",
    "errors = convention.get_validation_errors(catalog)\n",
    "if errors:\n",
    "    raise ValueError(f\"Catalog validation failed: {errors}\")\n",
    "\n",
    "print(f\"Catalog: {catalog.name}\")\n",
    "print(f\"  Tags: {len(catalog.tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SCHEMA ===\n",
    "schema = Schema(\n",
    "    name=SCHEMA_NAME,\n",
    "    catalog_name=catalog.name,\n",
    "    owner=schema_owner,\n",
    "    comment=\"World Bank indicator metadata for vector search\",\n",
    ")\n",
    "\n",
    "convention.apply_to(schema, environment)\n",
    "errors = convention.get_validation_errors(schema)\n",
    "if errors:\n",
    "    raise ValueError(f\"Schema validation failed: {errors}\")\n",
    "\n",
    "print(f\"Schema: {schema.fqdn}\")\n",
    "print(f\"  Tags: {len(schema.tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VECTOR SEARCH ENDPOINT ===\n",
    "vs_endpoint = VectorSearchEndpoint(\n",
    "    name=ENDPOINT_NAME,\n",
    "    comment=\"Semantic search endpoint for risk analytics indicators\",\n",
    "    tags=[\n",
    "        Tag(key=\"purpose\", value=\"semantic_search\"),\n",
    "        Tag(key=\"model\", value=\"databricks-bge-large-en\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "convention.apply_to(vs_endpoint, environment)\n",
    "errors = convention.get_validation_errors(vs_endpoint)\n",
    "if errors:\n",
    "    raise ValueError(f\"Endpoint validation failed: {errors}\")\n",
    "\n",
    "print(f\"Endpoint: {vs_endpoint.resolved_name}\")\n",
    "print(f\"  Tags: {len(vs_endpoint.tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VECTOR SEARCH INDEX ===\n",
    "FULL_TABLE_NAME = f\"{catalog.name}.{schema.name}.{TABLE_NAME}\"\n",
    "\n",
    "vs_index = VectorSearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    source_table=FULL_TABLE_NAME,\n",
    "    primary_key=\"indicator_id\",\n",
    "    embedding_column=\"embedding_text\",\n",
    "    embedding_model=\"databricks-bge-large-en\",\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    tags=[\n",
    "        Tag(key=\"index_type\", value=\"managed_embedding\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "convention.apply_to(vs_index, environment)\n",
    "errors = convention.get_validation_errors(vs_index)\n",
    "if errors:\n",
    "    raise ValueError(f\"Index validation failed: {errors}\")\n",
    "\n",
    "print(f\"Index: {vs_index.resolved_name}\")\n",
    "print(f\"  Source: {vs_index.source_table}\")\n",
    "print(f\"  Endpoint: {vs_index.resolved_endpoint_name}\")\n",
    "print(f\"  Tags: {len(vs_index.tags)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Deploy with BrickKit Executors\n",
    "\n",
    "BrickKit executors handle:\n",
    "- Idempotent create (skip if exists)\n",
    "- Wait for provisioning\n",
    "- Tag application\n",
    "- Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === INITIALIZE CLIENTS AND EXECUTORS ===\n",
    "\n",
    "ws_client = WorkspaceClient()\n",
    "vs_client = VectorSearchClient()\n",
    "\n",
    "catalog_executor = CatalogExecutor(ws_client, dry_run=DRY_RUN)\n",
    "schema_executor = SchemaExecutor(ws_client, dry_run=DRY_RUN)\n",
    "endpoint_executor = VectorSearchEndpointExecutor(ws_client, dry_run=DRY_RUN)\n",
    "index_executor = VectorSearchIndexExecutor(ws_client, dry_run=DRY_RUN)\n",
    "\n",
    "print(f\"Executors initialized (dry_run={DRY_RUN})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEPLOY CATALOG ===\n",
    "result = catalog_executor.create(catalog)\n",
    "print(f\"Catalog: {result.operation.value} - {result.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEPLOY SCHEMA ===\n",
    "result = schema_executor.create(schema)\n",
    "print(f\"Schema: {result.operation.value} - {result.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WRITE DATA TO TABLE ===\n",
    "# Using PySpark DataFrame API (not spark.sql)\n",
    "\n",
    "if not DRY_RUN:\n",
    "    # Write with Delta format and Change Data Feed enabled\n",
    "    (\n",
    "        sample_df\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .option(\"delta.enableChangeDataFeed\", \"true\")\n",
    "        .mode(\"overwrite\")\n",
    "        .saveAsTable(FULL_TABLE_NAME)\n",
    "    )\n",
    "    \n",
    "    # Verify\n",
    "    count = spark.table(FULL_TABLE_NAME).count()\n",
    "    print(f\"Table: {FULL_TABLE_NAME} - {count} rows written\")\n",
    "else:\n",
    "    print(f\"[DRY RUN] Would write {sample_df.count()} rows to {FULL_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEPLOY VECTOR SEARCH ENDPOINT ===\n",
    "result = endpoint_executor.create(vs_endpoint)\n",
    "print(f\"Endpoint: {result.operation.value} - {result.message}\")\n",
    "\n",
    "# Wait for endpoint to be online (uses executor's built-in wait logic)\n",
    "if not DRY_RUN and result.operation.value == \"CREATE\":\n",
    "    print(\"Waiting for endpoint to be online...\")\n",
    "    if endpoint_executor.wait_for_endpoint(vs_endpoint):\n",
    "        print(f\"Endpoint {vs_endpoint.resolved_name} is ONLINE\")\n",
    "    else:\n",
    "        raise RuntimeError(f\"Endpoint {vs_endpoint.resolved_name} failed to provision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEPLOY VECTOR SEARCH INDEX ===\n",
    "result = index_executor.create(vs_index)\n",
    "print(f\"Index: {result.operation.value} - {result.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Test Vector Search\n",
    "\n",
    "The index syncs asynchronously. Once ready, we can run similarity searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CHECK INDEX STATUS ===\n",
    "\n",
    "if not DRY_RUN:\n",
    "    FULL_INDEX_NAME = f\"{catalog.name}.{schema.name}.{vs_index.resolved_name}\"\n",
    "    \n",
    "    index = vs_client.get_index(\n",
    "        endpoint_name=vs_endpoint.resolved_name,\n",
    "        index_name=FULL_INDEX_NAME,\n",
    "    )\n",
    "    status = index.describe().get(\"status\", {})\n",
    "    print(f\"Index status: ready={status.get('ready', 'UNKNOWN')}\")\n",
    "    print(f\"Message: {status.get('message', 'N/A')}\")\n",
    "else:\n",
    "    print(\"[DRY RUN] Would check index status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RUN SIMILARITY SEARCH ===\n",
    "\n",
    "if not DRY_RUN:\n",
    "    TEST_QUERY = \"poverty and inequality measures\"\n",
    "    \n",
    "    try:\n",
    "        results = index.similarity_search(\n",
    "            query_text=TEST_QUERY,\n",
    "            columns=[\"indicator_id\", \"indicator_name\", \"description\", \"topic\"],\n",
    "            num_results=5,\n",
    "        )\n",
    "        \n",
    "        print(f\"Search: '{TEST_QUERY}'\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        data = results.get(\"result\", {}).get(\"data_array\", [])\n",
    "        for i, row in enumerate(data, 1):\n",
    "            print(f\"{i}. [{row[3]}] {row[1]}\")\n",
    "            print(f\"   {row[2][:80]}...\")\n",
    "            print()\n",
    "            \n",
    "    except Exception as e:\n",
    "        if \"not ready\" in str(e).lower() or \"syncing\" in str(e).lower():\n",
    "            print(\"Index is still syncing. Please wait and try again.\")\n",
    "        else:\n",
    "            raise\n",
    "else:\n",
    "    print(\"[DRY RUN] Would run similarity search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. What BrickKit Added (Governance Value)\n",
    "\n",
    "Let's see what governance BrickKit applied automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GOVERNANCE SUMMARY ===\n",
    "\n",
    "def display_resource_governance(name: str, resource):\n",
    "    \"\"\"Display governance metadata for a resource.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Name (with environment suffix)\n",
    "    if hasattr(resource, 'resolved_name'):\n",
    "        print(f\"Name: {resource.resolved_name}\")\n",
    "    elif hasattr(resource, 'fqdn'):\n",
    "        try:\n",
    "            print(f\"Name: {resource.fqdn}\")\n",
    "        except ValueError:\n",
    "            print(f\"Name: {resource.name}\")\n",
    "    else:\n",
    "        print(f\"Name: {resource.name}\")\n",
    "    \n",
    "    # Owner\n",
    "    if hasattr(resource, 'owner') and resource.owner:\n",
    "        owner = resource.owner\n",
    "        print(f\"Owner: {owner.resolved_name} ({owner.principal_type.value})\")\n",
    "    \n",
    "    # Tags\n",
    "    if hasattr(resource, 'tags') and resource.tags:\n",
    "        print(f\"Tags ({len(resource.tags)}):\")\n",
    "        for tag in sorted(resource.tags, key=lambda t: t.key):\n",
    "            print(f\"  - {tag.key}: {tag.value}\")\n",
    "\n",
    "# Display governance for all resources\n",
    "display_resource_governance(\"CATALOG\", catalog)\n",
    "display_resource_governance(\"SCHEMA\", schema)\n",
    "display_resource_governance(\"VECTOR SEARCH ENDPOINT\", vs_endpoint)\n",
    "display_resource_governance(\"VECTOR SEARCH INDEX\", vs_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONVENTION RULES APPLIED ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CONVENTION RULES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Convention: {convention.name} (v{convention.version})\")\n",
    "print()\n",
    "\n",
    "for rule in convention.schema.rules:\n",
    "    mode = \"ENFORCED\" if rule.mode.value == \"enforced\" else \"ADVISORY\"\n",
    "    print(f\"[{mode}] {rule.rule}\")\n",
    "    \n",
    "print()\n",
    "print(\"What this means:\")\n",
    "print(\"- Catalogs MUST be owned by service principals (not users)\")\n",
    "print(\"- All resources MUST be owned by SP or Group (no individual users)\")\n",
    "print(\"- Resources SHOULD have cost_center and team tags\")\n",
    "print(\"- BrickKit validated all these rules before deployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === WHAT YOU DIDN'T HAVE TO DO ===\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WHAT BRICKKIT DID FOR YOU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "benefits = [\n",
    "    (\"Environment suffixes\", f\"All names automatically suffixed with '_{ENVIRONMENT}'\"),\n",
    "    (\"Governance tags\", f\"{len(catalog.tags)} tags auto-applied from convention\"),\n",
    "    (\"Ownership validation\", \"Verified catalog has SP owner, schema has Group owner\"),\n",
    "    (\"Idempotent deployment\", \"Executors skip if resource exists, sync tags if needed\"),\n",
    "    (\"Wait logic\", \"Built-in endpoint provisioning wait with timeout/retry\"),\n",
    "    (\"Consistent patterns\", \"Same governance across Catalog, Schema, Endpoint, Index\"),\n",
    "]\n",
    "\n",
    "for benefit, detail in benefits:\n",
    "    print(f\"\\n{benefit}:\")\n",
    "    print(f\"  {detail}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Without BrickKit, you would manually:\")\n",
    "print(\"  - Add environment suffixes to every resource name\")\n",
    "print(\"  - Remember which tags to apply (and apply them consistently)\")\n",
    "print(\"  - Validate ownership rules before deployment\")\n",
    "print(\"  - Write wait/retry logic for endpoint provisioning\")\n",
    "print(\"  - Handle idempotency (check exists, update tags, etc.)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This demo showed:\n",
    "\n",
    "1. **Convention Loading** - Governance rules from YAML\n",
    "2. **Governed Models** - `Catalog`, `Schema`, `VectorSearchEndpoint`, `VectorSearchIndex`\n",
    "3. **Executors** - Idempotent deployment with built-in wait logic\n",
    "4. **Automatic Governance** - Tags, naming, ownership validation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Modify `conventions/financial_services.yml` to change governance rules\n",
    "- Set `dry_run=false` to deploy for real\n",
    "- Try different environments (`dev`, `acc`, `prd`) to see naming changes\n",
    "- Add your own data source instead of sample indicators"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
